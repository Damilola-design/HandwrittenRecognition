{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#Encoding and Split data into Train/Test Sets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Tensorflow Keras CNN Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras.layers import Embedding, Input, MaxPool2D\n",
    "#Plot Images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "dataset = r'/Users/dammy/Downloads/data'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#Now the next step is to read each image in the data and create a label for each with the name of the folder\n",
    "data = []\n",
    "label = []\n",
    "\n",
    "SIZE = 128 #Crop the image to 128x128\n",
    "\n",
    "for folder in os.listdir(dataset):\n",
    "    for file in os.listdir(os.path.join(dataset, folder)): #select the folder inside dataset directory \n",
    "        if file.endswith(\"png\"):\n",
    "            label.append(folder) # use the foldaer name as label\n",
    "            img = cv2.imread(os.path.join(dataset, folder, file)) # selct the file inside folder from the dateset direcotory\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #Using cv2.COLOR_BGR2RGB color space conversion\n",
    "            im = cv2.resize(img_rgb, (SIZE,SIZE)) # resizing the image in the color conversion\n",
    "            data.append(im) # use the image file name as data\n",
    "        else:\n",
    "            continue"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#Now let’s convert the data into numerical values\n",
    "data_arr = np.array(data)\n",
    "label_arr = np.array(label)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#Now let’s use the Label encoder and normalize the data\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(label_arr)\n",
    "y = to_categorical(y,36)\n",
    "X = data_arr/255"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "#The next step is to split the dataset into 80% training and 20% test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)\n",
    "# X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "# X_test = tf.keras.utils.normalize(X_test, axis=1)\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)\n",
    "X.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7292, 128, 128, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#Now let’s build a neural network model for the task of Flower Recognition\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu', input_shape = (SIZE,SIZE,3)))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "# model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "# model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(rate=0.5))\n",
    "# model.add(Dense(36, activation = \"softmax\"))\n",
    "# model.summary()\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "input_data = Input(shape=(128, 128, 3), name='input')\n",
    "\n",
    "inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n",
    "\n",
    "inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "# CNN to RNN\n",
    "inner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\n",
    "inner = Dense(36, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
    "\n",
    "## RNN\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm1')(inner)\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm2')(inner)\n",
    "\n",
    "## OUTPUT\n",
    "inner = Flatten()(inner) \n",
    "inner = Dense(36, kernel_initializer='he_normal',name='dense2')(inner)\n",
    "y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "model = Model(inputs=input_data, outputs=y_pred)\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128, 128, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 128, 128, 32)      0         \n",
      "                                                                 \n",
      " max1 (MaxPooling2D)         (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 64, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " max2 (MaxPooling2D)         (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " max3 (MaxPooling2D)         (None, 32, 16, 128)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32, 16, 128)       0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 64, 1024)          0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 64, 36)            36900     \n",
      "                                                                 \n",
      " lstm1 (Bidirectional)       (None, 64, 512)           600064    \n",
      "                                                                 \n",
      " lstm2 (Bidirectional)       (None, 64, 512)           1574912   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 36)                1179684   \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 36)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,485,704\n",
      "Trainable params: 3,485,256\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Now let’s compile the neural network model\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "batch_size=32\n",
    "epochs=9\n",
    "history = model.fit(X_train,y_train, batch_size=batch_size,\n",
    "                              epochs = epochs,\n",
    "                              validation_data = (X_test,y_test),\n",
    "                              verbose = 1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/9\n",
      "104/183 [================>.............] - ETA: 9:58 - loss: 3.3619 - accuracy: 0.0799 "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Now let’s let the model if it recognize flowers properly\n",
    "categories = np.sort(os.listdir(dataset))\n",
    "fig, ax = plt.subplots(2,2, figsize=(25, 20))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        k = int(np.random.random_sample() * len(X_test))\n",
    "        if(categories[np.argmax(y_test[k])] == categories[np.argmax(model.predict(X_test)[k])]):\n",
    "            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='green')\n",
    "            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])], color='green')\n",
    "            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE, SIZE, 3), cmap='gray')\n",
    "        else:\n",
    "            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='red')\n",
    "            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])], color='red')\n",
    "            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE, SIZE, 3), cmap='gray')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}